<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-11-23 Sun 14:02 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Bidipta Sarkar</title>
<meta name="author" content="Bidipta Sarkar" />
<meta name="description" content="Bidipta Sarkar's Personal Homepage" />
<meta name="keywords" content="homepage, website, research, AI, RL, MARL, Vision, Graphics" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="home_style.css"/>
<link rel="stylesheet" type="text/css" href="style.css"/>
<script src="https://kit.fontawesome.com/1eb1a53221.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<script src="common_animations.js"></script>
<link rel="icon" type="image/x-icon" href="favicon.ico">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">

<div class="page-container">
<div class="topsection">

<div id="outline-container-titlebar-head">
<h2 id="titlebar-head">Bidipta Sarkar</h2>
<div id="nav-pages">
<input class="menu-btn" type="checkbox" id="menu-btn" /> <label class="menu-icon" for="menu-btn"><span class="navicon"></span></label>
<ul class="org-ul">

<li><a href="index.html">Home</a></li>
            
<li><a href="research/index.html">Research</a></li>
	    
<li><a href="art/index.html">Art Gallery</a></li>
            
<li><a href="blog/index.html">Blog</a></li>
</ul>
</div>
</div>

<div class="sidebar">
    <div id="sidebar-head">
        <span class="image">
            <img src="Bidipta_Sarkar_600_600.jpg" style="border-radius: 50%">
        </span>
    </div>
    <nav id="sidebar-nav">
        <div id="nav-icons">
            <ul>
                
                    <i><a href="mailto:bidipta.sarkar@eng.ox.ac.uk" class="fa fa-envelope"></a></i>
                
                    <i><a href="https://github.com/bsarkar321" class="fa fa-github"></a></i>
                
                    <i><a href="https://scholar.google.com/citations?user=wr9RgmcAAAAJ" class="ai ai-google-scholar-square"></a></i>
                
                    <!-- <i><a href="https://www.instagram.com/bidiptas13/" class="fa fa-instagram"></a></i> -->

		    <i><a href="https://twitter.com/bidiptas13" class="fa fa-twitter"></a></i>

		    <i><a href="https://youtube.com/@bidi_2" class="fa fa-youtube"></a></i>

            </ul>
        </div>    
    </nav>
</div>

<div class="content_inner">
        <section id="home">
	  <div class="container">

<p>
I am a first-year DPhil student in Engineering Science at the <a href="https://eng.ox.ac.uk/">University of Oxford</a> in the <a href="https://foersterlab.com/">FLAIR</a> and <a href="https://whirl.cs.ox.ac.uk/">WhiRL</a> labs, co-supervised by Professor <a href="https://www.jakobfoerster.com/">Jakob Foerster</a> and Professor <a href="https://whirl.cs.ox.ac.uk/pages/people/shimon.html">Shimon Whiteson</a>. I am funded by the <a href="https://www.ox.ac.uk/clarendon">Clarendon Fund Scholarship</a> in partnership with a Department of Engineering Science Studentship.<br />
</p>

<p>
I received my BS in Computer Science with Honors and Distinction at <a href="https://cs.stanford.edu">Stanford University</a> (2020-2024), where I was also a member of Professor <a href="https://dorsa.fyi">Dorsa Sadigh</a>'s <a href="https://iliad.stanford.edu/">ILIAD</a> lab since my sophomore year.<br />
</p>

<p>
I am interested in creating AI agents that can interact with their environment and safely work alongside humans and other autonomous agents, with a growing focus on integrating natural language into AI coordination. My research broadly spans three subfields of computer science:<br />
</p>

<p>
&bull; Multi-Agent Reinforcement Learning: Enabling independently trained agents to cooperate on a common task and form conventions.<br />
</p>

<p>
&bull; Vision: Capturing meaningful information about an agent's environment from sensors.<br />
</p>

<p>
&bull; Graphics: Simulating environments while balancing speed and realism.<br />
</p>

</div></section></div></div><hr>
<div id="outline-container-blog-post" class="outline-2">
<h2 id="blog-post">Posts</h2>
<div class="outline-text-2" id="text-blog-post">
</div>
<div id="outline-container-org6383c88" class="outline-3">
<h3 id="org6383c88">(May 2025) <a href="https://easyacademicwebsite.github.io/">Easy Academic Website Template (With Instructions)</a></h3>
</div>

<div id="outline-container-org4bb67da" class="outline-3">
<h3 id="org4bb67da">(November 2023, Video) <a href="https://youtu.be/wm4f0sdKIUA">My talk on Diverse Conventions for Human-AI Collaboration</a></h3>
</div>

<div id="outline-container-orgf9b0a60" class="outline-3">
<h3 id="orgf9b0a60">(August 2023, Blog Post) <a href="blog/overcooked_madrona/index.html">Overcooked in Thousands of Kitchens: Training Top Performing Agents in Under a Minute</a></h3>
</div>

<div id="outline-container-org5ae6644" class="outline-3">
<h3 id="org5ae6644">(Living Document) <a href="https://bsarkar321.github.io/emacs_setup/">Emacs Setup for macOS and GNU/Linux</a></h3>
<div class="outline-text-3" id="text-org5ae6644">
<hr>
</div>
</div>
</div>
<div id="outline-container-org6b5686f" class="outline-2">
<h2 id="org6b5686f">Publications</h2>
<div class="outline-text-2" id="text-org6b5686f">
</div>
<div id="outline-container-org249f037" class="outline-3">
<h3 id="org249f037">Evolution Strategies at the Hyperscale</h3>
<div class="outline-text-3" id="text-org249f037">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar*</span>, Mattie Fellows*, Juan Agustin Duque*, Alistair Letcher\(^\dagger\), Antonio Le√≥n Villares\(^\dagger\), Anya Sims\(^\dagger\), Dylan Cope\(^\dagger\), Jarek Liesen\(^\dagger\), Lukas Seier\(^\dagger\), Theo Wolf\(^\dagger\), Uljad Berdica\(^\dagger\), Alexander David Goldie, Aaron Courville, Karin Sevegnani, Shimon Whiteson*, Jakob Nicolaus Foerster*<br />
</p>

<p>
<i>arXiv preprint, November 2025</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2511.16652">Paper</a> / <a href="https://eshyperscale.github.io/">Website</a> / <a href="https://github.com/ESHyperscale/HyperscaleES">Code</a> / <a href="https://github.com/ESHyperscale/nano-egg">Nano-EGG Code</a><br />
</p>

</div>



<div id="org611eece" class="figure">
<p><img src="blog/hyperscale_es/diagram.png" alt="diagram.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org87d3e90" class="outline-3">
<h3 id="org87d3e90">Discrete Flow Matching is a Surprisingly Effective Post-training Method to Address Compound Error in Autoregressive Models</h3>
<div class="outline-text-3" id="text-org87d3e90">
<div class="outline-text-3-inner">
<p>
Kang Li*, <span class="underline">Bidipta Sarkar*</span>, Zheng Xiong*, Sascha Frey, Zilin Wang, Frensi Zejnullahu, Alfred Backhouse, Stefan Zohren, Anisoara Calinescu, Mihai Cucuringu\(^\dagger\), Jakob Foerster\(^\dagger\)<br />
</p>

<p>
<i>ACM International Conference on AI in Finance <b>(Oral)</b>, November 2025</i><br />
</p>

<p>
<a href="https://dl.acm.org/doi/pdf/10.1145/3768292.3770442">Paper</a><br />
</p>

</div>
</div>
</div>
<div id="outline-container-org3de72a9" class="outline-3">
<h3 id="org3de72a9">LOB-Bench: Benchmarking Generative AI for Finance &#x2013; an Application to Limit Order Book Data</h3>
<div class="outline-text-3" id="text-org3de72a9">
<div class="outline-text-3-inner">
<p>
Peer Nagy*, Sascha Frey*, Kang Li, <span class="underline">Bidipta Sarkar</span>, Svitlana Vyetrenko, Stefan Zohren, Ani Calinescu, Jakob Foerster<br />
</p>

<p>
<i>International Conference on Machine Learning (ICML), July 2025</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2502.09172">Paper</a> / <a href="https://lobbench.github.io/">Website</a> / <a href="https://github.com/peernagy/lob_bench">Code</a><br />
</p>
</div>


<div id="orgca36e32" class="figure">
<p><img src="old_reports/lobbench_img.png" alt="lobbench_img.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgf6136bd" class="outline-3">
<h3 id="orgf6136bd">Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning</h3>
<div class="outline-text-3" id="text-orgf6136bd">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Warren Xia, C. Karen Liu, Dorsa Sadigh<br />
</p>

<p>
<i>International Conference on Autonomous Agents and Multiagent Systems (AAMAS) <b>(Oral)</b>, May 2025</i><br />
<i>Stanford Senior Honors Thesis, May 2024</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2502.06060">Paper</a> / <a href="https://doi.org/10.25740/fr666rz8034">Stanford Digital Repository</a> / <a href="https://socialdeductionllm.github.io">Website</a> / <a href="https://github.com/SocialDeductionLLM/SocialDeductionLLM">Code</a> / <a href="https://huggingface.co/collections/bidiptas/social-deduction-llm-aamas-2025-678e24d75e32f9134511125f">Models</a> / <a href="old_reports/Bidipta_SocialDeduction_Poster.pdf">Poster</a><br />
</p>
</div>


<div id="org3fdf546" class="figure">
<p><img src="old_reports/AmongUsDiagrams.png" alt="AmongUsDiagrams.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org6038017" class="outline-3">
<h3 id="org6038017">Physically Grounded Vision-Language Models for Robotic Manipulation</h3>
<div class="outline-text-3" id="text-org6038017">
<div class="outline-text-3-inner">
<p>
Jensen Gao, <span class="underline">Bidipta Sarkar</span>, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, Dorsa Sadigh<br />
</p>

<p>
<i>International Conference on Robotics and Automation (ICRA), May 2024</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2309.02561">Paper</a> / <a href="https://iliad.stanford.edu/pg-vlm/">Website</a> / <a href="https://drive.google.com/file/d/17gbzrJSs8YjVafIrX4omR_rx6qLgXjUd/view">Video</a><br />
</p>
</div>


<div id="orgf617132" class="figure">
<p><img src="old_reports/vlm_image.png" alt="vlm_image.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgbfe1739" class="outline-3">
<h3 id="orgbfe1739">Diverse Conventions for Human-AI Collaboration</h3>
<div class="outline-text-3" id="text-orgbfe1739">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Andy Shih, Dorsa Sadigh<br />
</p>

<p>
<i>Conference on Neural Information Processing Systems (NeurIPS), December 2023</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2310.15414">Paper</a> / <a href="https://iliad.stanford.edu/Diverse-Conventions/">Website</a> / <a href="https://github.com/Stanford-ILIAD/Diverse-Conventions">Code</a> / <a href="https://youtu.be/wm4f0sdKIUA">Video</a> / <a href="old_reports/Bidipta_DiverseConventions_Poster.pdf">Poster</a><br />
</p>
</div>


<div id="org6970411" class="figure">
<p><img src="old_reports/XPHandshake.png" alt="XPHandshake.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org0268e26" class="outline-3">
<h3 id="org0268e26">An Extensible, Data-Oriented Architecture for High-Performance, Many-World Simulation</h3>
<div class="outline-text-3" id="text-org0268e26">
<div class="outline-text-3-inner">
<p>
Brennan Shacklett, Luc Guy Rosenzweig, Zhiqiang Xie, <span class="underline">Bidipta Sarkar</span>, Andrew Szot, Erik Wijmans, Vladlen Koltun, Dhruv Batra, Kayvon Fatahalian<br />
</p>

<p>
<i>Transactions on Graphics 2023</i><br />
</p>

<p>
<a href="https://madrona-engine.github.io/shacklett_siggraph23.pdf">Paper</a> / <a href="https://madrona-engine.github.io">Website</a> / <a href="https://github.com/bsarkar321/madrona_rl_envs">RL Environments</a> / <a href="blog/overcooked_madrona/index.html">Blog</a> / <a href="https://colab.research.google.com/github/bsarkar321/madrona_rl_envs/blob/master/overcooked_compiled_colab.ipynb">Colab</a><br />
</p>
</div>


<div id="orgb860b23" class="figure">
<p><img src="old_reports/madrona.png" alt="madrona.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgb06df79" class="outline-3">
<h3 id="orgb06df79">PantheonRL: A MARL Library for Dynamic Training Interactions</h3>
<div class="outline-text-3" id="text-orgb06df79">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar*</span>, Aditi Talati*, Andy Shih*, Dorsa Sadigh<br />
</p>

<p>
<i>Proceedings of the 36th AAAI Conference on Artificial Intelligence (Demo Track), February 2022</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2112.07013">Paper</a> / <a href="https://github.com/Stanford-ILIAD/PantheonRL">Code</a> / <a href="https://youtu.be/3-Pf3zh_Hpo">Video</a> / <a href="https://doi.org/10.1609/aaai.v36i11.21734">DOI</a> / <a href="old_reports/Bidipta_PantheonRL_Poster.pdf">Poster</a><br />
</p>
</div>


<div id="orge58d36f" class="figure">
<p><img src="old_reports/round_robin.png" alt="round_robin.png" /><br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga3e6102" class="outline-2">
<h2 id="orga3e6102">Workshop Papers</h2>
<div class="outline-text-2" id="text-orga3e6102">
</div>
<div id="outline-container-orga39645d" class="outline-3">
<h3 id="orga39645d">An Interactive Agent Foundation Model</h3>
<div class="outline-text-3" id="text-orga39645d">
<div class="outline-text-3-inner">
<p>
Zane Durante*, <span class="underline">Bidipta Sarkar*</span>, Ran Gong*, Rohan Taori, Yusuke Noda, Paul Tang, Ehsan Adeli, Shrinidhi Kowshika Lakshmikanth, Kevin Schulman, Arnold Milstein, Demetri Terzopoulos, Ade Famoti, Noboru Kuno, Ashley Llorens, Hoi Vo, Katsu Ikeuchi, Li Fei-Fei, Jianfeng Gao, Naoki Wake*, Qiuyuan Huang*<br />
</p>

<p>
<i>Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR) Workshops, June 2025</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2402.05929">Paper</a> / <a href="https://agentfoundationmodel.github.io/">Website</a><br />
</p>
</div>


<div id="org18cc807" class="figure">
<p><img src="old_reports/Agentframework.png" alt="Agentframework.png" /><br />
</p>
</div>

<hr>
</div>
</div>
</div>
<div id="outline-container-orgcf17950" class="outline-2">
<h2 id="orgcf17950">Other Projects</h2>
<div class="outline-text-2" id="text-orgcf17950">
</div>
<div id="outline-container-org7218f53" class="outline-3">
<h3 id="org7218f53">Temporally and Spatially Novel Video Frame Synthesis using 4D Video Autoencoder</h3>
<div class="outline-text-3" id="text-org7218f53">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Xinyi Wang, Kathy Yu<br />
</p>

<p>
<i>CS231n Final Project, Spring 2022</i><br />
</p>

<p>
(Best Project Poster Award)
</p>

<p>
<a href="http://cs231n.stanford.edu/reports/2022/pdfs/8.pdf">Report</a> / <a href="http://cs231n.stanford.edu/reports/2022/pdfs/8p.pdf">Poster</a> / <a href="https://twitter.com/drfeifei/status/1533840002735407104?s=46&amp;t=M7k1cW-r1qVcTdl16BlH-A">CS231n Tweet</a> / <a href="https://github.com/KathyFeiyang/cs231n-project">Code</a><br />
</p>
</div>


<div id="orgbe67159" class="figure">
<p><img src="old_reports/4dencoder.png" alt="4dencoder.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org9683f2a" class="outline-3">
<h3 id="org9683f2a">Simulating Food Interactions with Material Point Methods in Houdini</h3>
<div class="outline-text-3" id="text-org9683f2a">
<div class="outline-text-3-inner">
<p>
<i>CS348C Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/348c/bidipta_mpm.txt">Report</a> / <a href="old_reports/348c/mpm_houdini.hipnc">Houdini File</a> / <a href="old_reports/348c/mpm_houdini.mantra_ipr.mov">Video</a><br />
</p>
</div>


<div id="org2735140" class="figure">
<p><img src="old_reports/348c_img.png" alt="348c_img.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgecf3222" class="outline-3">
<h3 id="orgecf3222">Real-time Cel Shading</h3>
<div class="outline-text-3" id="text-orgecf3222">
<div class="outline-text-3-inner">
<p>
<i>CS248 Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/248/writeup.pdf">Report</a> / <a href="https://drive.google.com/file/d/1RBGs3V28lLoKfwNxFO9VhEpRoYSzle0C/view?usp=sharing">Video</a><br />
</p>
</div>


<div id="orgacb404b" class="figure">
<p><img src="old_reports/cel_shading.png" alt="cel_shading.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org14bae64" class="outline-3">
<h3 id="org14bae64">Virtual Hand Interactions with ARKit</h3>
<div class="outline-text-3" id="text-org14bae64">
<div class="outline-text-3-inner">
<p>
<i>CS231a Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/231a.pdf">Report</a> / <a href="https://github.com/bsarkar321/ARHandInteraction">Code</a> / <a href="https://drive.google.com/file/d/1Rh1sHnOpdZxG6oVDIftx-JYUXNY7n2GF/view?usp=sharing">Demo Video</a><br />
</p>
</div>


<div id="org05f2760" class="figure">
<p><img src="old_reports/ar_hands.png" alt="ar_hands.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orga95205d" class="outline-3">
<h3 id="orga95205d">The Guardian</h3>
<div class="outline-text-3" id="text-orga95205d">
<div class="outline-text-3-inner">
<p>
<i>CS148 Final Project, Fall 2022</i><br />
</p>

<p>
<a href="old_reports/148/bidiptas.pdf">Report</a> / <a href="old_reports/148/bidiptas.png">Final Image</a> / <a href="old_reports/148/bidiptas_a.png">View 2</a> / <a href="old_reports/148/bidiptas_b.png">No Material</a> / <a href="https://drive.google.com/drive/folders/1lzNt7bS1suecTQy8GmH74S8LIcLHL-1y">Blend File</a><br />
</p>
</div>


<div id="orge124e57" class="figure">
<p><img src="old_reports/148/bidiptas.png" alt="bidiptas.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orge761e43" class="outline-3">
<h3 id="orge761e43">Multi-Agent Self-Learning Tank Game</h3>
<div class="outline-text-3" id="text-orge761e43">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Henry Ang<br />
</p>

<p>
<i>CS221 Final Project, Spring 2021</i><br />
</p>

<p>
<a href="old_reports/221.pdf">Report</a> / <a href="https://github.com/guohaoang/TankGym">Code</a> / <a href="https://youtu.be/kcZmCApSudY">Video</a><br />
</p>
</div>


<div id="org1016fa2" class="figure">
<p><img src="old_reports/221.jpeg" alt="221.jpeg" /><br />
</p>
</div>

<hr>
</div>
</div>
</div>
<div id="outline-container-orgf96931a" class="outline-2">
<h2 id="orgf96931a">Teaching and Service</h2>
<div class="outline-text-2" id="text-orgf96931a">
</div>
<div id="outline-container-orgf1b00c3" class="outline-3">
<h3 id="orgf1b00c3">Peer Reviewer</h3>
<div class="outline-text-3" id="text-orgf1b00c3">
<p>
ICLR 2025, ICML 2025, ICRA 2025, IEEE RA-L (Oct 2024, April 2025), NeurIPS (2024, 2025), IEEE SMC 2025<br />
</p>
</div>
</div>
<div id="outline-container-orgaab78a5" class="outline-3">
<h3 id="orgaab78a5">Stanford Center for Teaching and Learning CS Tutor</h3>
<div class="outline-text-3" id="text-orgaab78a5">

<div id="org8255c79" class="figure">
<p><img src="old_reports/CTL.png" alt="CTL.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orge139686" class="outline-3">
<h3 id="orge139686">Tau Beta Pi Mentor</h3>
<div class="outline-text-3" id="text-orge139686">

<div id="orgf331068" class="figure">
<p><img src="old_reports/TBP.png" alt="TBP.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgc117d76" class="outline-3">
<h3 id="orgc117d76">Section Leader (CS 106A and 106B)</h3>
<div class="outline-text-3" id="text-orgc117d76">

<div id="orgd0069c9" class="figure">
<p><img src="old_reports/198.png" alt="198.png" height="100 em" /><br />
</p>
</div>

<hr>

        <div class="footer">
	  <p id="copyright">
            &copy; 2023 Bidipta Sarkar
	  </p>
	</div>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
