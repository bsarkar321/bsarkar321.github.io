<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-10-05 Sat 15:25 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Bidipta Sarkar</title>
<meta name="author" content="Bidipta Sarkar" />
<meta name="description" content="Bidipta Sarkar's Personal Homepage" />
<meta name="keywords" content="homepage, website, research, AI, RL, MARL, Vision, Graphics" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="home_style.css"/>
<link rel="stylesheet" type="text/css" href="style.css"/>
<script src="https://kit.fontawesome.com/1eb1a53221.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<script src="common_animations.js"></script>
<link rel="icon" type="image/x-icon" href="favicon.ico">
</head>
<body>
<div id="content" class="content">

<div class="page-container">
<div class="topsection">

<div id="outline-container-titlebar-head">
<h2 id="titlebar-head">Bidipta Sarkar</h2>
<div id="nav-pages">
<input class="menu-btn" type="checkbox" id="menu-btn" /> <label class="menu-icon" for="menu-btn"><span class="navicon"></span></label>
<ul class="org-ul">

<li><a href="index.html">Home</a></li>
            
<li><a href="research/index.html">Research</a></li>
	    
<li><a href="art/index.html">Art Gallery</a></li>
            
<li><a href="blog/index.html">Blog</a></li>
</ul>
</div>
</div>

<div class="sidebar">
    <div id="sidebar-head">
        <span class="image">
            <img src="Bidipta_Sarkar_600_600.jpg" style="border-radius: 50%">
        </span>
    </div>
    <nav id="sidebar-nav">
        <div id="nav-icons">
            <ul>
                
                    <i><a href="mailto:bidipta.sarkar@eng.ox.ac.uk" class="fa fa-envelope"></a></i>
                
                    <i><a href="https://github.com/bsarkar321" class="fa fa-github"></a></i>
                
                    <i><a href="https://scholar.google.com/citations?user=wr9RgmcAAAAJ" class="ai ai-google-scholar-square"></a></i>
                
                    <!-- <i><a href="https://www.instagram.com/bidiptas13/" class="fa fa-instagram"></a></i> -->

		    <i><a href="https://twitter.com/bidiptas13" class="fa fa-twitter"></a></i>

		    <i><a href="https://youtube.com/@bidi_2" class="fa fa-youtube"></a></i>

            </ul>
        </div>    
    </nav>
</div>

<div class="content_inner">
        <section id="home">
	  <div class="container">

<p>
I am a first-year DPhil student in Engineering Science at the <a href="https://eng.ox.ac.uk/">University of Oxford</a> as a member of Professor <a href="https://www.jakobfoerster.com/">Jakob Foerster</a>'s <a href="https://foersterlab.com/">FLAIR</a> lab. I am funded by the <a href="https://www.ox.ac.uk/clarendon">Clarendon Fund Scholarship</a> in partnership with a Department of Engineering Science Studentship.<br />
</p>

<p>
I received my BS in Computer Science at <a href="https://cs.stanford.edu">Stanford University</a> (2020-2024), where I was also a member of Professor <a href="https://dorsa.fyi">Dorsa Sadigh</a>'s <a href="https://iliad.stanford.edu/">ILIAD</a> lab since my sophomore year.<br />
</p>

<p>
I am interested in creating AI agents that can interact with their environment and safely work alongside humans and other autonomous agents. My research broadly spans three subfields of computer science:<br />
</p>

<p>
&bull; Multi-Agent Reinforcement Learning: Enabling independently trained agents to cooperate on a common task and form conventions.<br />
</p>

<p>
&bull; Vision: Capturing meaningful information about an agent's environment from sensors.<br />
</p>

<p>
&bull; Graphics: Simulating environments while balancing speed and realism.<br />
</p>

</div></section></div></div><hr>
<div id="outline-container-blog-post" class="outline-2">
<h2 id="blog-post">Posts</h2>
<div class="outline-text-2" id="text-blog-post">
</div>
<div id="outline-container-org7742bdf" class="outline-3">
<h3 id="org7742bdf">(November 2023, Video) <a href="https://youtu.be/wm4f0sdKIUA">My talk on Diverse Conventions for Human-AI Collaboration</a></h3>
</div>

<div id="outline-container-org6f6cb08" class="outline-3">
<h3 id="org6f6cb08">(August 2023, Blog Post) <a href="blog/overcooked_madrona/index.html">Overcooked in Thousands of Kitchens: Training Top Performing Agents in Under a Minute</a></h3>
</div>

<div id="outline-container-org30bc2ee" class="outline-3">
<h3 id="org30bc2ee">(Living Document) <a href="https://bsarkar321.github.io/emacs_setup/">Emacs Setup for macOS and GNU/Linux</a></h3>
<div class="outline-text-3" id="text-org30bc2ee">
<hr>
</div>
</div>
</div>
<div id="outline-container-org080a0da" class="outline-2">
<h2 id="org080a0da">Publications</h2>
<div class="outline-text-2" id="text-org080a0da">
</div>
<div id="outline-container-org494a111" class="outline-3">
<h3 id="org494a111">Physically Grounded Vision-Language Models for Robotic Manipulation</h3>
<div class="outline-text-3" id="text-org494a111">
<div class="outline-text-3-inner">
<p>
Jensen Gao, <span class="underline">Bidipta Sarkar</span>, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, Dorsa Sadigh<br />
</p>

<p>
<i>International Conference on Robotics and Automation (ICRA), May 2024</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2309.02561">Paper</a> / <a href="https://iliad.stanford.edu/pg-vlm/">Website</a> / <a href="https://drive.google.com/file/d/17gbzrJSs8YjVafIrX4omR_rx6qLgXjUd/view">Video</a><br />
</p>
</div>


<div id="org793dd63" class="figure">
<p><img src="old_reports/vlm_image.png" alt="vlm_image.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org4bc7626" class="outline-3">
<h3 id="org4bc7626">Diverse Conventions for Human-AI Collaboration</h3>
<div class="outline-text-3" id="text-org4bc7626">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Andy Shih, Dorsa Sadigh<br />
</p>

<p>
<i>Conference on Neural Information Processing Systems (NeurIPS), December 2023</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2310.15414">Paper</a> / <a href="https://iliad.stanford.edu/Diverse-Conventions/">Website</a> / <a href="https://github.com/Stanford-ILIAD/Diverse-Conventions">Code</a> / <a href="https://youtu.be/wm4f0sdKIUA">Video</a><br />
</p>
</div>


<div id="org127df7c" class="figure">
<p><img src="old_reports/XPHandshake.png" alt="XPHandshake.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgca61515" class="outline-3">
<h3 id="orgca61515">An Extensible, Data-Oriented Architecture for High-Performance, Many-World Simulation</h3>
<div class="outline-text-3" id="text-orgca61515">
<div class="outline-text-3-inner">
<p>
Brennan Shacklett, Luc Guy Rosenzweig, Zhiqiang Xie, <span class="underline">Bidipta Sarkar</span>, Andrew Szot, Erik Wijmans, Vladlen Koltun, Dhruv Batra, Kayvon Fatahalian<br />
</p>

<p>
<i>Transactions on Graphics 2023</i><br />
</p>

<p>
<a href="https://madrona-engine.github.io/shacklett_siggraph23.pdf">Paper</a> / <a href="https://madrona-engine.github.io">Website</a> / <a href="https://github.com/bsarkar321/madrona_rl_envs">RL Environments</a> / <a href="file:///Users/bidiptasarkar/Desktop/iCloudDrive/personal_website/blog/overcooked_madrona/index.html">Blog</a> / <a href="https://colab.research.google.com/github/bsarkar321/madrona_rl_envs/blob/master/overcooked_compiled_colab.ipynb">Colab</a><br />
</p>
</div>


<div id="orgcc4a3aa" class="figure">
<p><img src="old_reports/madrona.png" alt="madrona.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org89167e1" class="outline-3">
<h3 id="org89167e1">PantheonRL: A MARL Library for Dynamic Training Interactions</h3>
<div class="outline-text-3" id="text-org89167e1">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar*</span>, Aditi Talati*, Andy Shih*, Dorsa Sadigh<br />
</p>

<p>
<i>Proceedings of the 36th AAAI Conference on Artificial Intelligence (Demo Track), February 2022</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2112.07013">Paper</a> / <a href="https://github.com/Stanford-ILIAD/PantheonRL">Code</a> / <a href="https://youtu.be/3-Pf3zh_Hpo">Video</a> / <a href="https://doi.org/10.1609/aaai.v36i11.21734">DOI</a><br />
</p>
</div>


<div id="orgc69c12b" class="figure">
<p><img src="old_reports/round_robin.png" alt="round_robin.png" /><br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf29f29c" class="outline-2">
<h2 id="orgf29f29c">Bachelor's Honors Thesis</h2>
<div class="outline-text-2" id="text-orgf29f29c">
</div>
<div id="outline-container-orgfabea02" class="outline-3">
<h3 id="orgfabea02">Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning</h3>
<div class="outline-text-3" id="text-orgfabea02">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Warren Xia, C. Karen Liu, Dorsa Sadigh<br />
</p>

<p>
<i>Stanford Digital Repository, May 2024</i><br />
</p>

<p>
<a href="https://doi.org/10.25740/fr666rz8034">Paper</a> / <a href="https://github.com/SocialDeductionLLM">Website</a> / <a href="https://github.com/SocialDeductionLLM">Code</a> / <a href="https://doi.org/10.25740/fr666rz8034">DOI</a><br />
</p>
</div>


<div id="orgabb213a" class="figure">
<p><img src="old_reports/AmongUsDiagrams.png" alt="AmongUsDiagrams.png" /><br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org4a9cb96" class="outline-2">
<h2 id="org4a9cb96">Preprints</h2>
<div class="outline-text-2" id="text-org4a9cb96">
</div>
<div id="outline-container-org7f6201c" class="outline-3">
<h3 id="org7f6201c">An Interactive Agent Foundation Model</h3>
<div class="outline-text-3" id="text-org7f6201c">
<div class="outline-text-3-inner">
<p>
Zane Durante*, <span class="underline">Bidipta Sarkar*</span>, Ran Gong*, Rohan Taori, Yusuke Noda, Paul Tang, Ehsan Adeli, Shrinidhi Kowshika Lakshmikanth, Kevin Schulman, Arnold Milstein, Demetri Terzopoulos, Ade Famoti, Noboru Kuno, Ashley Llorens, Hoi Vo, Katsu Ikeuchi, Li Fei-Fei, Jianfeng Gao, Naoki Wake*, Qiuyuan Huang*<br />
</p>

<p>
<i>arXiv, February 2024</i><br />
</p>

<p>
<a href="https://arxiv.org/abs/2402.05929">Paper</a> / <a href="https://agentfoundationmodel.github.io/">Website</a><br />
</p>
</div>


<div id="orgf590997" class="figure">
<p><img src="old_reports/Agentframework.png" alt="Agentframework.png" /><br />
</p>
</div>

<hr>
</div>
</div>
</div>
<div id="outline-container-org4df5ce8" class="outline-2">
<h2 id="org4df5ce8">Other Projects</h2>
<div class="outline-text-2" id="text-org4df5ce8">
</div>
<div id="outline-container-org282a675" class="outline-3">
<h3 id="org282a675">Temporally and Spatially Novel Video Frame Synthesis using 4D Video Autoencoder</h3>
<div class="outline-text-3" id="text-org282a675">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Xinyi Wang, Kathy Yu<br />
</p>

<p>
<i>CS231n Final Project, Spring 2022</i><br />
</p>

<p>
(Best Project Poster Award)
</p>

<p>
<a href="http://cs231n.stanford.edu/reports/2022/pdfs/8.pdf">Report</a> / <a href="http://cs231n.stanford.edu/reports/2022/pdfs/8p.pdf">Poster</a> / <a href="https://twitter.com/drfeifei/status/1533840002735407104?s=46&amp;t=M7k1cW-r1qVcTdl16BlH-A">CS231n Tweet</a> / <a href="https://github.com/KathyFeiyang/cs231n-project">Code</a><br />
</p>
</div>


<div id="org347cdc2" class="figure">
<p><img src="old_reports/4dencoder.png" alt="4dencoder.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org102e66d" class="outline-3">
<h3 id="org102e66d">Simulating Food Interactions with Material Point Methods in Houdini</h3>
<div class="outline-text-3" id="text-org102e66d">
<div class="outline-text-3-inner">
<p>
<i>CS348C Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/348c/bidipta_mpm.txt">Report</a> / <a href="old_reports/348c/mpm_houdini.hipnc">Houdini File</a> / <a href="old_reports/348c/mpm_houdini.mantra_ipr.mov">Video</a><br />
</p>
</div>


<div id="org92a1858" class="figure">
<p><img src="old_reports/348c_img.png" alt="348c_img.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org26713e2" class="outline-3">
<h3 id="org26713e2">Real-time Cel Shading</h3>
<div class="outline-text-3" id="text-org26713e2">
<div class="outline-text-3-inner">
<p>
<i>CS248 Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/248/writeup.pdf">Report</a> / <a href="https://drive.google.com/file/d/1RBGs3V28lLoKfwNxFO9VhEpRoYSzle0C/view?usp=sharing">Video</a><br />
</p>
</div>


<div id="orgbd09dce" class="figure">
<p><img src="old_reports/cel_shading.png" alt="cel_shading.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgd229a0f" class="outline-3">
<h3 id="orgd229a0f">Virtual Hand Interactions with ARKit</h3>
<div class="outline-text-3" id="text-orgd229a0f">
<div class="outline-text-3-inner">
<p>
<i>CS231a Final Project, Winter 2022</i><br />
</p>

<p>
<a href="old_reports/231a.pdf">Report</a> / <a href="https://github.com/bsarkar321/ARHandInteraction">Code</a> / <a href="https://drive.google.com/file/d/1Rh1sHnOpdZxG6oVDIftx-JYUXNY7n2GF/view?usp=sharing">Demo Video</a><br />
</p>
</div>


<div id="org24fea15" class="figure">
<p><img src="old_reports/ar_hands.png" alt="ar_hands.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org663bebc" class="outline-3">
<h3 id="org663bebc">The Guardian</h3>
<div class="outline-text-3" id="text-org663bebc">
<div class="outline-text-3-inner">
<p>
<i>CS148 Final Project, Fall 2022</i><br />
</p>

<p>
<a href="old_reports/148/bidiptas.pdf">Report</a> / <a href="old_reports/148/bidiptas.png">Final Image</a> / <a href="old_reports/148/bidiptas_a.png">View 2</a> / <a href="old_reports/148/bidiptas_b.png">No Material</a> / <a href="https://drive.google.com/drive/folders/1lzNt7bS1suecTQy8GmH74S8LIcLHL-1y">Blend File</a><br />
</p>
</div>


<div id="orga8e0df5" class="figure">
<p><img src="old_reports/148/bidiptas.png" alt="bidiptas.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org67890d4" class="outline-3">
<h3 id="org67890d4">Multi-Agent Self-Learning Tank Game</h3>
<div class="outline-text-3" id="text-org67890d4">
<div class="outline-text-3-inner">
<p>
<span class="underline">Bidipta Sarkar</span>, Henry Ang<br />
</p>

<p>
<i>CS221 Final Project, Spring 2021</i><br />
</p>

<p>
<a href="old_reports/221.pdf">Report</a> / <a href="https://github.com/guohaoang/TankGym">Code</a> / <a href="https://youtu.be/kcZmCApSudY">Video</a><br />
</p>
</div>


<div id="org7000815" class="figure">
<p><img src="old_reports/221.jpeg" alt="221.jpeg" /><br />
</p>
</div>

<hr>
</div>
</div>
</div>
<div id="outline-container-org694d054" class="outline-2">
<h2 id="org694d054">Teaching and Outreach</h2>
<div class="outline-text-2" id="text-org694d054">
</div>
<div id="outline-container-org028ec2f" class="outline-3">
<h3 id="org028ec2f">Stanford Center for Teaching and Learning CS Tutor</h3>
<div class="outline-text-3" id="text-org028ec2f">

<div id="orgf4ea81f" class="figure">
<p><img src="old_reports/CTL.png" alt="CTL.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-org424e2f1" class="outline-3">
<h3 id="org424e2f1">Tau Beta Pi Mentor</h3>
<div class="outline-text-3" id="text-org424e2f1">

<div id="org815170f" class="figure">
<p><img src="old_reports/TBP.png" alt="TBP.png" /><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgaf8e2f1" class="outline-3">
<h3 id="orgaf8e2f1">Section Leader (CS 106A and 106B)</h3>
<div class="outline-text-3" id="text-orgaf8e2f1">

<div id="org57b848c" class="figure">
<p><img src="old_reports/198.png" alt="198.png" height="100 em" /><br />
</p>
</div>

<hr>

        <div class="footer">
	  <p id="copyright">
            &copy; 2023 Bidipta Sarkar
	  </p>
	</div>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
